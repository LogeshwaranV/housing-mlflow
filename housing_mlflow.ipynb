{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306d4920",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484e774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90e933d",
   "metadata": {},
   "source": [
    "## Download the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c3a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "fetch_housing_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8afd3f",
   "metadata": {},
   "source": [
    "## Load the dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e25dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2baeada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_names = \"total_rooms\", \"total_bedrooms\", \"population\", \"households\"\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = [\n",
    "    housing.columns.get_loc(c) for c in col_names]\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "def train_test(data):\n",
    "    housing=data\n",
    "    train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "    housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "        strat_train_set = housing.loc[train_index]\n",
    "        strat_test_set = housing.loc[test_index]\n",
    "    \n",
    "    return strat_train_set,strat_test_set\n",
    "    \n",
    "    \n",
    "    \n",
    "def data_prep(data):\n",
    "    housing=data\n",
    "    \n",
    "    housing_labels = housing[\"median_house_value\"].copy()\n",
    "    housing = housing.drop(\"median_house_value\", axis=1)\n",
    "    \n",
    "    \n",
    "    housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "    \n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    num_attribs = list(housing_num)\n",
    "    cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "    \n",
    "    housing_prepared = full_pipeline.fit_transform(housing)\n",
    "    \n",
    "    return housing_prepared,housing_labels\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1717bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow server --backend-store-uri mlruns/ --default-artifact-root mlruns/ --host 0.0.0.0 --port 5000\n",
    "\n",
    "remote_server_uri = \"http://0.0.0.0:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b5fef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://0.0.0.0:5000'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38544906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlruns/2', experiment_id='2', lifecycle_stage='active', name='Housing', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"Housing\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925d0292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(forest_reg, actual, pred):\n",
    "    # compute relevant metrics\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "518561c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(max_features=8, n_estimators=30):\n",
    "    # train a model with given parameters\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "\n",
    "    data_path = \"datasets/housing/housing.csv\"\n",
    "    \n",
    "\n",
    "    # Useful for multiple runs (only doing one run in this sample notebook)    \n",
    "    with mlflow.start_run(run_name='PARENT_housing') as parent_run:\n",
    "        mlflow.log_param(\"parent\", \"yes\")\n",
    "        with mlflow.start_run(run_name='CHILD_DATA_PREP', nested=True) as child_run:\n",
    "            mlflow.log_param(\"child\", \"yes\")\n",
    "            data = load_data()\n",
    "    \n",
    "            train_data, test_data = train_test(data)\n",
    "    \n",
    "            train_x, train_y = data_prep(train_data)\n",
    "    \n",
    "            test_x, test_y = data_prep(test_data)\n",
    "        \n",
    "        with mlflow.start_run(run_name='CHILD_TRAIN_MODEL', nested=True) as child_run:\n",
    "            mlflow.log_param(\"child\", \"yes\")\n",
    "        \n",
    "            forest_reg=RandomForestRegressor(max_features=max_features, n_estimators=n_estimators, random_state=42)\n",
    "       \n",
    "            forest_reg.fit(train_x, train_y)\n",
    "        \n",
    "        with mlflow.start_run(run_name='CHILD_SCORING', nested=True) as child_run:\n",
    "            mlflow.log_param(\"child\", \"yes\")\n",
    "        \n",
    "            # Evaluate Metrics\n",
    "            predicted = forest_reg.predict(test_x)\n",
    "            (rmse, mae, r2) = eval_metrics(forest_reg, test_y, predicted)\n",
    "\n",
    "        # Print out metrics\n",
    "        print(\"Random Forest model (max_features=%f, n_estimators=%f):\" % (max_features, n_estimators))\n",
    "        print(\"  rmse: %s\" % rmse)\n",
    "        print(\"  mae: %s\" % mae)\n",
    "        print(\"  r2_score: %s\" % r2)\n",
    "\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(key=\"max_features\", value=max_features)\n",
    "        mlflow.log_param(key=\"n_estimators\", value=n_estimators)\n",
    "        mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "        mlflow.log_metrics({\"mae\": mae, \"r2_score\": r2})\n",
    "        mlflow.log_artifact(data_path)\n",
    "        print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "        \n",
    "        mlflow.sklearn.log_model(forest_reg, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a56f1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model (max_features=8.000000, n_estimators=30.000000):\n",
      "  rmse: 70466.35579577027\n",
      "  mae: 52196.55785691215\n",
      "  r2_score: 0.619009430380601\n",
      "Save to: mlruns/2/37217c37ecbd4556871aa5c9760c8a2d/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(8,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16a54709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model (max_features=7.000000, n_estimators=25.000000):\n",
      "  rmse: 67489.71449387146\n",
      "  mae: 49968.91187984496\n",
      "  r2_score: 0.6505172187496944\n",
      "Save to: mlruns/2/dca4a931b94a4aa5a08033999d5475f3/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(7,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ace2246f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model (max_features=5.000000, n_estimators=10.000000):\n",
      "  rmse: 66118.25234969275\n",
      "  mae: 48755.6238372093\n",
      "  r2_score: 0.6645766185566665\n",
      "Save to: mlruns/2/c29dc5355aec44d5b23c063f3ec7fb95/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "687493c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model (max_features=2.000000, n_estimators=5.000000):\n",
      "  rmse: 67249.17211282428\n",
      "  mae: 49138.40993217054\n",
      "  r2_score: 0.6530039861262631\n",
      "Save to: mlruns/2/65f6f31380504c0fbd05971569ab85b4/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09ee85e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model (max_features=6.000000, n_estimators=20.000000):\n",
      "  rmse: 66732.50340117687\n",
      "  mae: 49607.764643895345\n",
      "  r2_score: 0.6583153758426179\n",
      "Save to: mlruns/2/c3e56c9783124e64ad78f08d39ecf16b/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(6,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d67b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle-dev",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
